{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>TD3: Les arbres de décision (partie 1)</center>\n",
    "\n",
    "Nous allons travailler cette semaine sur les arbres de décision.\n",
    "\n",
    "Nous allons d'abord développer l'algorithme à la main afin de bien comprendre comment il fonctionne. Dans le monde professionnel, il ne faudra surtout pas utiliser un programme de classification développer à la main car il ne sera pas optimisé. Nous le faisons ici dans un but pédagogique afin de bien comprendre comment il fonctionne et pour le maitriser.\n",
    "\n",
    "Nous allons développer un programme qui construit un arbre de décision. Le jeu de données qui est stocké dans le fichier *magasin.csv* concerne une étude marketing réalisée dans le cadre de la vente de vêtements dans un magasin dédié. Le jeu de données comprend 4 variables caractéristiques qui sont des nombres: le prix du vêtement, sa qualité (notée entre 0 et 100), son degré d'adéquation aux tendances de la mode au moment de l'enquête (noté entre 0 et 100), ses coloris qui interpellent ou non (noté entre 0 et 100). La variable cible qui est un nombre (0 ou 1) détermine si le vêtement a été acheté ou non.\n",
    "Le but de cette classification et d'obtenir les règles qui permettent de modèliser le processus d'achat d'un vêtement en fonction des 4 variables caractéristiques.\n",
    "\n",
    "\n",
    "Votre travail consiste à écrire le code de certaines parties qui manquent dans les cellules ci-dessous\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "import operator\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charger les données stockées dans *magasin.csv* dans un dataframe et l'afficher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "df_magasin = pd.read_csv('data/magasin.csv',sep=';')\n",
    "df_magasin\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous avez ci-dessous la classe *noeud* qui correspondra à un noeud de l'arbre de décision. \n",
    "Vous n'avez rien à développer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Noeud:\n",
    "   \"\"\"Cette classe a pour but de représenter les branches de l'arbre de\n",
    "   classification.\n",
    "   \"\"\"   \n",
    "   def __init__(self, feature, value,df_left_branch, df_right_branch, depth, effectif):\n",
    "      self.feature = feature\n",
    "      self.value = value\n",
    "      self.left_branch = df_left_branch\n",
    "      self.right_branch = df_right_branch\n",
    "      self.depth = depth\n",
    "      self.effectif = effectif \n",
    "       \n",
    "   \"\"\" Cette méthode permet de retourner la chaine de  caractère qui représente une régle de l'arbre de décision\"\"\"\n",
    "   def split(self):\n",
    "          return self.feature + ' <= ' + str(self.value)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous avez ci-dessous la classe *feuille* qui correspondra à une feuille de l'arbre de décision. \n",
    "Vous n'avez rien à développer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feuille:\n",
    "  \"\"\"Cette classe a pour but de représenter les feuilles de notre arbre de\n",
    "  décision\n",
    "  \"\"\"\n",
    "  def __init__(self, df_dataset, effectif, classe_predite, probabilites):\n",
    "    self.dataset = df_dataset\n",
    "    self.effectif = effectif\n",
    "    self.classe_predite = classe_predite\n",
    "    self.probabilites = probabilites\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction qui permet d'afficher les noeuds et les feuilles d'un arbre de décision\n",
    "Rien à développer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_arbre_decision(branche, decalage=\"\"):\n",
    "  \"\"\"Affichage de l'arbre de décision \n",
    "  INPUT \n",
    "     - branche : branche à afficher (noeud ou feuille)\n",
    "     - decalage: pour décaler l'affichage, utilisé dans la récursivité\n",
    "    \"\"\"\n",
    "\n",
    "  \n",
    "  # Différents affichages si c'est une feuille \n",
    "  if isinstance(branche, Feuille):\n",
    "      print (decalage +\"Predict\", branche.classe_predite)\n",
    "      print (decalage +\"Predict\", branche.probabilites)\n",
    "      return\n",
    "\n",
    "  # Affichage de la condition de la séparation\n",
    "  print (decalage+ branche.split())\n",
    "\n",
    "  # Dans le cas où la condition est vérifiée\n",
    "  print (decalage + '--> True:')\n",
    "  print_arbre_decision(branche.left_branch,decalage +\"  \")\n",
    "\n",
    "  # Dans le cas où la condition n'est pas vérifiée\n",
    "  print(decalage + '--> False:')\n",
    "  print_arbre_decision(branche.right_branch,decalage + \"  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les méthodes dont le code est manquant (TODO) doivent être développées.\n",
    "Tester vos méthodes une à une (test unitaire).  \n",
    "\n",
    "Des cas d'usage vous sont aussi demandés dans certaines cellules ci-dessous. Vous ne pourrez bien sûr les mettre en place que lorsque vous aurez développé certaines méthodes de la classe. Cette possibilité sera indiquée dans un commentaire dans la méthode au fur à mesure que vous avancerez dans le développement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arbre_decision :\n",
    "  \"\"\" Cette classe a pour but de créer un algorithme d'apprentissage automatique\n",
    "  d'arbres de décision classifieur\"\"\"\n",
    "\n",
    "\n",
    " # méthode donnée\n",
    "  def __init__(self, target_feature, df_dataset, max_depth):\n",
    "    \"\"\"Constructeur \n",
    "   PARAMETRES\n",
    "    - target_feature : chaine de caractère qui correspond la variable cible qu'il faudra classifier\n",
    "    par exemple ici, \"Achat\"\n",
    "    - df_dataset : toutes les données d'apprentissage (un dataframe)\n",
    "    - max_depth : la profondeur maximale de l'arbre à entraîner\n",
    "    \n",
    "   \"\"\"\n",
    "    self.target_feature = target_feature\n",
    "    self.df_dataset = df_dataset\n",
    "    self.max_depth = max_depth\n",
    "    \n",
    "\n",
    "    # méthode donnée\n",
    "  def creer_feuille(self, df_data_feuille):\n",
    "    \"\"\" Création d'une feuille \n",
    "    PARAMETRES\n",
    "       - df_data_feuille : dataframe contenant les données concernant la feuille à construire\n",
    "    RESULTAT\n",
    "       - feuille : la classe feuille créée avec les informations de df_data_feuille\"\"\"\n",
    "\n",
    "    target = df_data_feuille[self.target_feature]\n",
    "    effectif = target.shape[0]\n",
    "    dict_targets_count=Counter(target)\n",
    "    classe_predite = max(dict_targets_count.items(), key=operator.itemgetter(1))[0]\n",
    "    probabilites = {l: label_count/effectif for l, label_count in dict_targets_count.items()}\n",
    "    return Feuille(df_data_feuille, effectif, classe_predite, probabilites)\n",
    "\n",
    "#TODO\n",
    "  def decouper_dataset_en_2(self, feature, value, df_dataset):\n",
    "   \"\"\"Cette fonction sépare les données en 2 en fonction\n",
    "   de la valeur 'value' de la variable quantitative 'feature' passée en paramètre.\n",
    "  \n",
    "   PARAMETRES\n",
    "    - feature : chaine de caractère correspondant à la variable à séparer\n",
    "    - value : nombre correspondant à la valeur à laquelle séparer notre jeu de données\n",
    "    - df_dataset : pandas dataframe à séparer\n",
    "   RESULTAT\n",
    "   On retourne 2 dataframe\n",
    "    - left : dataframe avec les données où 'feature' est plus petit ou égale à 'value'\n",
    "    - right : dataframe avec les données où 'feature' est plus grand que 'value' \n",
    "   \"\"\"\n",
    "   \n",
    "   left = df_dataset[df_dataset.loc[:,feature]<= value]\n",
    "   right = df_dataset[df_dataset.loc[:,feature]> value]\n",
    "   return left, right\n",
    "  \n",
    "#TODO\n",
    "  def calculer_probabilites_carre(self, df_target):\n",
    "    \"\"\"Calculer les probabilités au carré pour chaque classe de valeur de la variable cible \n",
    "    PARAMETRES\n",
    "    df_target la variable cible\n",
    "    RESULTAT\n",
    "       un tableau contenant les probabilités au carré associées à chaque classe de valeur de la variable cible\n",
    "    \"\"\"\n",
    "    total_count = df_target.shape[0]\n",
    "    return [(count / total_count)*(count /total_count)\n",
    "           for count in Counter(df_target).values()]\n",
    "\n",
    "  #TODO\n",
    "  def calculer_gini(self, df_dataset):\n",
    "    \"\"\"Calcul du coefficient Gini du dataset \n",
    "    PARAMETRES\n",
    "       - df_dataset : dataframe pour lequel il faut calculer le coefficient de Gini\n",
    "    RESULTAT\n",
    "       le coefficient Gini calculé à partir du dataset en entrée\n",
    "    \"\"\"\n",
    "    rows = df_dataset[self.target_feature]\n",
    "    p=self.calculer_probabilites_carre(rows)\n",
    "    impurity=1-np.sum(p)\n",
    "    return impurity\n",
    "  \n",
    "  #TODO après avoir développer toutes les méthodes ci-dessous vous pourrez tester le cas d'usage 1\n",
    "  def calculer_cout_separation_en_2(self, df_dataset_gauche, df_dataset_droit):\n",
    "    \"\"\" Calculer le coût d'une séparation d'un noeud en deux branches\n",
    "    PARAMETRES\n",
    "       - df_dataset_gauche : dataset de la branche de gauche\n",
    "       - df_dataset_droit : dataset de la branche de droite\n",
    "    RESULTAT\n",
    "       coût de la séparation\"\"\"\n",
    "    eval_gauche = self.calculer_gini(df_dataset_gauche)\n",
    "    nb_left = df_dataset_gauche.shape[0]\n",
    "    right_eval = self.calculer_gini(df_dataset_droit)\n",
    "    nb_right = df_dataset_droit.shape[0]\n",
    "    nb_tot = nb_left + nb_right\n",
    "    cout = nb_left/nb_tot * eval_gauche + nb_right/nb_tot * right_eval\n",
    "    return cout\n",
    "  \n",
    "  \n",
    "  #TODO\n",
    "  def calcul_couts_separation(self, df_dataset, feature):\n",
    "    \"\"\" calculer les coûts de toutes les séparations possibles d'une variable feature\n",
    "    PARAMETRES\n",
    "       - df_dataset : dataset étudié\n",
    "       - feature : variable du dataset à évaluer\n",
    "    RESULTAT \n",
    "       dataframe contenant le coût de chaque séparation\"\"\" \n",
    "\n",
    "    df_couts = pd.DataFrame([], columns=('feature', 'value', 'cost'))\n",
    "    value_to_test = df_dataset.loc[:, feature].sort_values().unique()\n",
    "    for value in value_to_test :\n",
    "      left, right = self.decouper_dataset_en_2(feature, value, df_dataset)\n",
    "      cost_result = self.calculer_cout_separation_en_2(left, right)\n",
    "      df_couts = pd.concat([df_couts,pd.DataFrame([[feature, \n",
    "                                              value,\n",
    "                                              cost_result]],\n",
    "                                            columns=('feature', 'value', 'cost'))])\n",
    "    return df_couts\n",
    "  \n",
    "  #TODO\n",
    "  def trouver_meilleure_séparation(self, df_dataset):\n",
    "    \"\"\" Trouver la meilleure séparation du dataset passé en paramètre\n",
    "    PARAMETRES \n",
    "       - df_dataset : dataframe qui contient les données à séparer\n",
    "    RESULTAT \n",
    "       un dataframe comprenant 3 colonnes nommées: 'feature' variable à séparer, 'value' \n",
    "       la valeur à laquelle séparer la variable, et 'cost' le coût de cette séparation. \n",
    "       Les données de ces colonnes seront les données relatives à la meilleure séparation trouvée\"\"\"\n",
    "    \n",
    "    df_meilleure_separation = pd.DataFrame([], columns=('feature', 'value', 'cost'))\n",
    "    #on recupère le nom des colonnes liées aux caractéristiques (pas cible)\n",
    "    columns = df_dataset.columns[np.logical_not(df_dataset.columns == self.target_feature)]\n",
    "    for column in columns : \n",
    "     df_meilleure_separation =pd.concat([df_meilleure_separation, self.calcul_couts_separation(df_dataset, column)])\n",
    "\n",
    "    df_meilleure_separation = df_meilleure_separation.reset_index(drop=True)\n",
    "    idx_cout_min = df_meilleure_separation['cost'].idxmin(axis=0, skipna=True)\n",
    "    return df_meilleure_separation.iloc[idx_cout_min, :]\n",
    "   \n",
    "\n",
    "  \n",
    "\n",
    "  #TODO\n",
    "  def entrainer(self, df_dataset, depth=0):\n",
    "      \"\"\"Cette fonction construit l'arbre de décision relative aux jeux de données df_dataset\n",
    "      PARAMETRES \n",
    "         - depth : profondeur actuel de l'arbre, 0 pour l'initialisation\n",
    "         - df_dataset: le dataframe qui contient le jeu de données\n",
    "      RESULTAT\n",
    "         - node : racine de l'arbre\n",
    "      \"\"\"\n",
    "      # Cette partie de code vérifie que le dataset peut encore être séparé\n",
    "      no_more_split = True\n",
    "      columns = df_dataset.columns[np.logical_not(df_dataset.columns == self.target_feature)]\n",
    "      for column in columns : \n",
    "        if len(df_dataset[column].unique()) > 1 :\n",
    "          no_more_split = False\n",
    "         \n",
    "      # Si le dataset est pure, ou que la profondeur maximum est atteinte ou\n",
    "      # que le dataset ne peut plus être séparé nous créons une feuille\n",
    "      if len(df_dataset[self.target_feature].unique())==1 or depth==self.max_depth or no_more_split:\n",
    "        return self.creer_feuille(df_dataset)\n",
    "\n",
    "      # Recherche de la meilleure séparation\n",
    "      split_eval = self.trouver_meilleure_séparation(df_dataset)\n",
    "\n",
    "      # Si le coût obtenu après séparation est moins bon que le coût actuel, \n",
    "      # création d'une feuille avec le dataset actuel\n",
    "      if split_eval['cost'] >= self.calculer_gini(df_dataset) :\n",
    "          return self.creer_feuille(df_dataset)\n",
    "\n",
    "      left_branch, right_branch = self.decouper_dataset_en_2(split_eval['feature'], split_eval['value'], df_dataset)\n",
    "\n",
    "      # Entraînement récursif de la branche de gauche\n",
    "      left_node = self.entrainer(left_branch, depth+1)\n",
    "\n",
    "      # Entraînement récursif de la branche de droite\n",
    "      right_node = self.entrainer(right_branch, depth+1)\n",
    "      \n",
    "      # On retourne la racine de l'arbre\n",
    "      return Noeud(split_eval['feature'], \n",
    "                  split_eval['value'], \n",
    "                  left_node,\n",
    "                  right_node,\n",
    "                  depth,\n",
    "                  df_dataset.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Premier cas d'usage\n",
    "\n",
    "- utiliser la méthode *creer_feuille* sur le jeu de données initial\n",
    "- afficher pour cette feuille l'attribut *prediction*, *effectif* et *probabilite*\n",
    "\n",
    "> Résultats à obtenir\n",
    "\n",
    "> 0 pour la classe prédite (la classe: Non Achat ici)  \n",
    "> 78 pour l'effectif de la classe  \n",
    "> les probabilités pour la régle: 0.51 pour la classe 0 et 0.48 pour la classe 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbre_decision = Arbre_decision('Achat', df_magasin, 4)\n",
    "feuille_classif = arbre_decision.creer_feuille(df_magasin)\n",
    "print(feuille_classif.classe_predite)\n",
    "print(feuille_classif.effectif)\n",
    "print(feuille_classif.probabilites)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second cas d'usage\n",
    "\n",
    "- découper le dataset initial en 2 en utilisant la valeur \"Mode\" égal à 50\n",
    "- calculer le coût de séparation en 2\n",
    "\n",
    "> on doit trouver: 0,47\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbre_decision = Arbre_decision('Achat', df_magasin, 4)\n",
    "left_classif, right_classif = arbre_decision.decouper_dataset_en_2('Mode', 50, df_magasin)\n",
    "cout=arbre_decision.calculer_cout_separation_en_2(left_classif,right_classif)\n",
    "print(cout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troisième cas d'usage\n",
    "\n",
    "- calculer le tableau des coûts de séparation relatifs à la variable \"Mode\"\n",
    "- donner la meilleure séparation \n",
    "\n",
    "> vous devez obtenir: *valeur 80 et coût de 0.43*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cout=arbre_decision.calcul_couts_separation(df_magasin,'Mode')\n",
    "df_meilleur=arbre_decision.trouver_meilleure_séparation(df_magasin)\n",
    "df_meilleur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quatrième cas d'usage\n",
    "\n",
    "- trouver la meilleure séparation du dataset initial\n",
    "- découper le dataset en 2 à partir de la caractéristique et de la valeur trouvée précédemment\n",
    "- créer le noeud correspondant\n",
    "- afficher la régle de décision trouvée (méthode split() de noeud)\n",
    "\n",
    "> *Mode <= 80* doit s'afficher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbre_decision =Arbre_decision('Achat', df_magasin, 4)\n",
    "feature, value, cost = arbre_decision.trouver_meilleure_séparation(df_magasin)\n",
    "left_branch, right_branch = arbre_decision.decouper_dataset_en_2(feature, value, df_magasin)\n",
    "branch = Noeud(feature, value,left_branch, right_branch, 0, 100)\n",
    "\n",
    "print(branch.split())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cinquième cas d'utilisation\n",
    "\n",
    "Afficher l'arbre de décision relatif au jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "arbre_decision = Arbre_decision('Achat', df_magasin, 4)\n",
    "arbre_entraine = arbre_decision.entrainer(df_magasin)\n",
    "print_arbre_decision(arbre_entraine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
