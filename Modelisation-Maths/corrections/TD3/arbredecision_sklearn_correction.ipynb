{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tLjW850U41CK"
   },
   "source": [
    "# <center>TD3: arbres de décision avec *scikit-learn* </center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qeuOIK-9tYrN"
   },
   "source": [
    "Nous allons utiliser *scikit-learn* pour mettre en place des arbres de décision. Voici le lien [doc](https://scikit-learn.org/stable/modules/tree.html) vers la documentation de *scikit-learn* concernant les arbres de décision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DhWqONh8D63I"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\alexa\\Downloads\\corrections\\TD3\\arbredecision_sklearn_correction.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alexa/Downloads/corrections/TD3/arbredecision_sklearn_correction.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Importation des packages\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/alexa/Downloads/corrections/TD3/arbredecision_sklearn_correction.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtree\u001b[39;00m \u001b[39mimport\u001b[39;00m DecisionTreeClassifier\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alexa/Downloads/corrections/TD3/arbredecision_sklearn_correction.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alexa/Downloads/corrections/TD3/arbredecision_sklearn_correction.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m \u001b[39mimport\u001b[39;00m tree\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# Importation des packages\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Première partie: utilisation de la classe *DecisionTreeClassifier*\n",
    "\n",
    "Nous allons commencer à travailler avec le jeu de données *magasin.csv* que vous connaissez bien maintenant.\n",
    "Déterminer un dataframe *X* qui contiendra toutes les variables caractéristiques et un dataframe *Y* la variable cible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\alexa\\Downloads\\corrections\\TD3\\arbredecision_sklearn_correction.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/alexa/Downloads/corrections/TD3/arbredecision_sklearn_correction.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_magasin \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mdata/magasin.csv\u001b[39m\u001b[39m'\u001b[39m,sep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m;\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alexa/Downloads/corrections/TD3/arbredecision_sklearn_correction.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m Y\u001b[39m=\u001b[39mdf_magasin\u001b[39m.\u001b[39mloc[:,\u001b[39m'\u001b[39m\u001b[39mAchat\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alexa/Downloads/corrections/TD3/arbredecision_sklearn_correction.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(Y)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df_magasin = pd.read_csv('data/magasin.csv',sep=';')\n",
    "Y=df_magasin.loc[:,'Achat']\n",
    "print(Y)\n",
    "X=df_magasin.iloc[:,1:]\n",
    "\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En vous aidant de la documentation de *scikit-learn*, entrainer le modèle (construction de l'arbre de décision) et faire afficher l'arbre de décision construit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation des paramètres du modèle\n",
    "model_tree = DecisionTreeClassifier()\n",
    "\n",
    "# Entraînement du modèle d'arbre\n",
    "model_tree.fit(X, Y)\n",
    "\n",
    "# Visualisation de l'arbre\n",
    "tree.plot_tree(model_tree)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez à l'aide du code ci-dessous avoir une meilleure représentation de l'arbre.\n",
    "Comparer l'arbre obtenu à celui que vous aviez construit avec votre programme écrit à la main. Il y a des différences.\n",
    "En étudiant dans la documentation, les paramètres que l'on a la possibilité  d'utiliser pour construire l'arbre avec *DecisionTreeClassifier*, essayez de voir quelques différences.   \n",
    "\n",
    "> Eh oui, on est loin d'avoir implémenter complètement cet algorithme, il y a de nombreux critères à prendre en compte pour pouvoir optimiser l'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "columns = X.columns[np.logical_not(X.columns == \"Achat\")]\n",
    "\n",
    "\n",
    "dot_data = tree.export_graphviz(model_tree, out_file=None,\n",
    "                                feature_names=columns.to_list(),\n",
    "                                class_names=['non achat','achat'],\n",
    "                                filled=True, rounded=True,\n",
    "                                special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "#graph.render(\"magasin\")\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seconde partie: optimisation du modèle \n",
    " \n",
    "> dans le monde de l'apprentissage automatique, on adore les néologismes issus de la langue anglaise => vous verrez souvent ce terme: *fine-tuner* le modèle. \n",
    "\n",
    "Le but sera de tester différentes valeurs des hyperparamètres du modèle pour l'optimiser. On utilisera pour cela la technique de la validation croisée comme dans le TD précédent.\n",
    "Nous utiliserons le jeu de données *iris* qui est plus volumineux que le premier utilisé. \n",
    "\n",
    "- charger le jeu de données *iris*\n",
    "- déterminer un ensemble d'apprentissage et un ensemble de test (60% apprentissage et 40% test). Dans la méthode que vous utiliserez pour construire ces deux ensembles, intéressez vous au paramètre *random_state* et passez lui la valeur maximale suggérée.\n",
    "> Le jeu de données *iris* est un jeu de données très simple dont le modèle est assez facile à déterminé. Si l'on veut voir une différence après la validation croisée sur les résultats de prédiction, il faut rendre l'apprentissage plus difficile d'où la répartition ensemble d'apprentissage et ensemble de test choisi.\n",
    "\n",
    "- construire un arbre de décision relatif à ce jeu de donnée et faire afficher l'arbre\n",
    "- calculer le score obtenu sur l'ensemble de test (exactitude)\n",
    "\n",
    "> lancer plusieurs fois votre traitement (10 fois). Qu'observez vous par rapport à la valeur de l'exactitude de la prédiction sur l'ensemble de test ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "\n",
    "iris = load_iris()\n",
    "X, Y = iris.data, iris.target\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.6, random_state=42)\n",
    "arbre_decision = tree.DecisionTreeClassifier()\n",
    "arbre_decision.fit(X_train, Y_train)\n",
    "tree.plot_tree(arbre_decision, filled=True)\n",
    "arbre_decision.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant étudier 2 hyperparamètres du modèle: *max_depth* et *min_samples_leaf*\n",
    "\n",
    "- regarder dans la documentation en quoi ces deux hyperparamètres influencent la construction de l'arbre. Vous pouvez tester à la main plusieurs de leurs valeurs pour visualiser les conséquences de leur modification sur le modèle obtenu.\n",
    "- déterminer à l'aide de la technique de la validation croisée, la meilleure valeur pour les 2 hyperparamètres précédents.\n",
    "Vous utiliserai la classe *GridSearchCV* qui permet de réaliser tous les tests avec les hyperparamètres concernés et vous donnera les valeurs de ceux-ci optimisés pour maximiser l'exactitude\n",
    "[documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "et [exemple](https://www.mygreatlearning.com/blog/gridsearchcv/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(iris.data, iris.target,\n",
    "    test_size=0.4, random_state=42)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parametre_grid = {\"max_depth\": [1, 2, 3, 4, 5, 6, 7],\n",
    "      \"min_samples_split\": [2, 3, 5, 10, 15, 20]}\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid=parametre_grid, cv=5)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Attention à l'interprétation: ce sont les meilleures valeurs des hyperparamètres de notre modèle pour le jeu de données que nous utilisons et avec la séparation que nous avons mis en place (60% apprentissage et 40% test)\n",
    "\n",
    "Utiliser les valeurs des paramètres déterminées précédemment sur la partition initiale des données (60% apprentissage et 40% test). Que constatez vous ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "\n",
    "iris = load_iris()\n",
    "X, Y = iris.data, iris.target\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.60, random_state=42)\n",
    "arbre_decision = tree.DecisionTreeClassifier(max_depth=4, min_samples_split= 2)\n",
    "arbre_decision.fit(X_train, Y_train)\n",
    "tree.plot_tree(arbre_decision, filled=True)\n",
    "# moyenne de l'accuracy\n",
    "arbre_decision.score(X_test,Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un autre cas à étudier\n",
    "\n",
    "\n",
    "Utiliser maintenant le jeu de données relatif au Titanic. Nous utiliserons les colonnes qui sont notées dans la cellule suivante de ce notebook.\n",
    "\n",
    "- séparer les données en 2 ensembles: aprentissage => 80% et test=> 20%\n",
    "- construire l'arbre de décision\n",
    "- calculer le score obtenu sur l'ensemble de test\n",
    "- optimiser les hyperparamètres\n",
    "- afficher le nouveau score obtenu et les valeurs des hyperparamètres déterminées par la phase d'optimisation (les hyperparamètres à optimiser sont donnés dans la cellule suivante de ce notebook)\n",
    "\n",
    "> attention: afin d'utiliser la classe *DecisionTreeClassifier*,  il faut que:\n",
    "- toutes les valeurs liées aux caractéristiques du jeu de données soient des nombres\n",
    "- qu'aucune valeur du jeu de données ne soit nulle (vide)  \n",
    "*Pour la colonne *Age* vous remplacerez les valeurs nulles par la moyenne de l'âge des passagers.\n",
    "Pour les valeurs nulles dans les autres colonnes, vous supprimerez la ligne du jeu de données qui correspond à cette valeur nulle.\n",
    "Il faudra donc mettre en place un pré-traitement sur les données avant de construire l'arbre.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Charger le jeu de données complet\n",
    "df = pd.read_csv('data/titanic.csv', sep='\\t' )\n",
    "\n",
    "# Prétraitement des données (nous allons utiliser uniquement ces colonnes)\n",
    "selected_columns = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked' ,'Survived']\n",
    "df = df[selected_columns]\n",
    "\n",
    "# Gérer les valeurs manquantes (remplacer les valeurs manquantes de 'age' par la moyenne)\n",
    "df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "# Convertir la colonne 'Sex' en une colonne binaire (0 pour male, 1 pour female)\n",
    "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "df['Embarked']=df['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
    "\n",
    "# Découper le jeu de données en deux parties => X et Y:\n",
    "# la première partie X correspond aux caractéristiques (donc toutes les colonnes sauf 'Survived')\n",
    "# la seconde partie Y ne comprend que les données qui correspondent à la classe (la cible) qui ici est constituée de la la colonne 'Survived'\n",
    "X = df.drop('Survived', axis=1)  # Les caractéristiques\n",
    "Y = df['Survived']              # La variable cible (Survived)\n",
    "\n",
    "# Division en 80% pour l'apprentissage et 20% pour le test (regarder la fonction: train_test_split(...))\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "arbre_decision = tree.DecisionTreeClassifier()\n",
    "arbre_decision.fit(X_train, Y_train)\n",
    "\n",
    "print(arbre_decision.score(X_test,Y_test))\n",
    "\n",
    "params = {\n",
    "    'criterion':  ['gini', 'entropy'],\n",
    "    'max_depth':  [None, 2, 4, 6, 8, 10],\n",
    "    'max_features': [None, 'sqrt', 'log2', 0.2, 0.4, 0.6, 0.8],\n",
    "    'splitter': ['best', 'random']\n",
    "}\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid=params, cv=5)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "print(grid_search.best_estimator_.score(X_test, Y_test))\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_search.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En Résumé:\n",
    "\n",
    "Les arbres de décision ont plusieurs avantages qui les rendent intéressants dans des contextes où il est utile de comprendre la séquence de décisions prise par le modèle :\n",
    "\n",
    "- Ils sont simples à comprendre et à visualiser.\n",
    "\n",
    "- Ils nécessitent peu de préparation des données (pas de normalisation, etc.).\n",
    "\n",
    "- Le coût d’utilisation des arbres est logarithmique.\n",
    "\n",
    "- Ils sont capables d’utiliser des données catégorielles et numériques.\n",
    "\n",
    "- Ils sont capables de traiter des problèmes multi-classe.\n",
    "\n",
    "- Le résultat est directement visualisable.\n",
    "\n",
    "**Ces modèles présentent néanmoins deux désavantages majeurs :**\n",
    "\n",
    "- Sur-apprentissage : parfois les arbres générés sont trop complexes et généralisent mal. Choisir des bonnes valeurs pour les paramètres profondeur maximale (max_depth) et nombre minimal d’exemples par feuille (min_samples_leaf) permet d’éviter ce problème.\n",
    "\n",
    "- Il peut arriver que les arbres générés ne soient pas équilibrés (ce qui implique que le temps de parcours n’est plus logarithmique). Il est donc recommandé d’ajuster le jeu de données avant la construction, pour éviter qu’une classe domine largement les autres (en termes de nombre d’exemples d’apprentissage).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOE9pjqr0ZKO/sqrDLKutle",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Arbres de décision classifieur sklearn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
