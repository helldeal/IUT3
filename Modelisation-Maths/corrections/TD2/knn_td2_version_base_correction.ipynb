{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> TD2 Modèlisation Mathématique </center>\n",
    "\n",
    "\n",
    "Nous allons développer cette semaine l'algorithme des *k* plus proches voisins.\n",
    "\n",
    "Nous allons d'abord le développer à la main. \n",
    "\n",
    "> *Dans le monde professionnel, il ne faudra surtout pas utiliser un programme de classification développé à la main car il ne sera pas optimisé. Nous le réalisons ici dans un but pédagogique afin de bien comprendre comment il fonctionne et pour le maîtriser.*\n",
    "\n",
    "Nous verrons en fin de ce TD comment utiliser la bibliothèque *scikit-learn* pour mettre en place ce classifieur de manière très aisée.\n",
    "\n",
    "L'algorithme des *k plus proches voisins* est un algorithme de classification.  \n",
    "Il n'y a pas à proprement parlé dans cet algorithme de phase d'apprentissage comme nous en verrons dans d'autres algorithmes. \n",
    "L'ensemble d'apprentissage correspond aux données qui sont classées. L'ensemble de test est constitué de données à classer pour tester l'algorithme.\n",
    "\n",
    "La phase de prédiction consiste pour chaque élément de l'ensemble de test à prédire son étiquette en déterminant la classe majoritaire de ses *k* plus proches voisins qui sera alors la sienne.\n",
    "\n",
    "Nous allons travailler avec un jeu de données \"jouet\" conçu pour tester les algorithmes sur des exemples simples (*make_circles*).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chargement des bibliothèques python\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "# pour générer le jeu de données\n",
    "from sklearn.datasets import make_circles\n",
    "#pour calculer l'exactitude (accuracy) de la prédiction\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Mise en place des données\n",
    "\n",
    "Nous allons ici générer le jeu de données. Nous aurons:\n",
    " - les données et les étiquettes d'apprentissage: *x_train* et *y_train* (de taille 100)\n",
    " - les données et les étiquettes de test: *x_test* et *y_test* (de taille 50)\n",
    "\n",
    " Ce sont ces données de test que nous classifierons (*x_test*) en nous appuyant sur la classification des données d'apprentissage.\n",
    " \n",
    " Nous évaluerons la classification obtenue des élèments de *x_test* par rapport à la classification réelle de ces élèments (*y_test*)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#génération des ensembles de données et des étiquettes, regarder la documentation de make_circles\n",
    "\n",
    "x_train , y_train = make_circles(100, noise=0, random_state=1)\n",
    "x_test , y_test = make_circles(50, noise=0.1, random_state=1)\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant visualiser ces données (apprentissage et test). Utiliser plt.scatter(...) pour visualiser tous les points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "\n",
    "plt.scatter(x_train[y_train==0][:, 0], x_train[y_train==0][:, 1], c='green')\n",
    "plt.scatter(x_train[y_train==1][:, 0], x_train[y_train==1][:, 1], c='orange')\n",
    "\n",
    "plt.scatter(x_test[y_test==0][:, 0], x_test[y_test==0][:, 1], c='pink')\n",
    "plt.scatter(x_test[y_test==1][:, 0], x_test[y_test==1][:, 1], c='black')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Développement de la classe *KnnClassifieur*\n",
    "\n",
    "Nous allons écrire une classe *python* nommée *KnnClassifieur* qui va nous permettre de réaliser le classifieur.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "class KnnClassifieur:\n",
    "\n",
    "#constructeur\n",
    "#parametre:\n",
    "#k: le nombre de voisins \n",
    "#x_train: contient les éléments dont on connait la classe, 1 ligne = 1 élèment\n",
    "#y_train: contient les étiquettes des classes des éléments de x_train qui sont des entiers\n",
    "\n",
    "\n",
    "  def __init__(self, k: int,x_train: np.ndarray, y_train: np.ndarray):\n",
    "    self.k = k\n",
    "    self.x_train = x_train\n",
    "    self.y_train = y_train\n",
    "\n",
    "\n",
    "  @staticmethod\n",
    "  #calcule la distance euclidienne entre 2 vecteurs x et y\n",
    "  #Parametres:\n",
    "  #x: le premier vecteur\n",
    "  #y: le second vecteur\n",
    "  #Retour:\n",
    "  #la distance euclidienne entre x et y\n",
    "\n",
    "  def distance_euclidienne(x: np.ndarray, y: np.ndarray):\n",
    "    return np.sqrt(np.sum(np.square(x-y)))\n",
    "\n",
    "  \n",
    "#prédit l'étiquette de la classe d'un élèment du test\n",
    "#Parametre:\n",
    "#une ligne de l'ensemble de test qui correspond à l'élément à classer\n",
    "#Retour\n",
    "#l'étiquette de la classe prédite qui est un entier\n",
    "\n",
    "  def predict_etiquette(self, x_test_ligne: np.ndarray) -> int:\n",
    "    distances=[]\n",
    "    #on itère sur les lignes du x_train\n",
    "    for j in range(len(self.x_train)):\n",
    "      distance=KnnClassifieur.distance_euclidienne(x_test_ligne,self.x_train[j,:])\n",
    "      distances.append(distance)\n",
    "    distances=np.array(distances)\n",
    "    #distances_k_plus_proche est un tableau d'une ligne qui contient les k plus proches voisins (ce sont les indices qui sont stockés)\n",
    "    #sa taille est de k\n",
    "    distances_k_plus_proche=np.argsort(distances)[:self.k]\n",
    "    #on recupere les étiquettes de ces k plus proches voisins\n",
    "    etiquettes=self.y_train[distances_k_plus_proche]\n",
    "    #détermination de l'étiquette majoritaire dans etiquettes\n",
    "    etiquette=mode(etiquettes, keepdims=True)\n",
    "    #on ne récupère que l'étiquette majoritaire\n",
    "    etiquette=etiquette.mode[0]\n",
    "    return etiquette\n",
    "\n",
    "    \n",
    "#prédit toutes les étiquettes des classes des éléments de x_test\n",
    "#Parametres:\n",
    "#x_test: les éléments à classer\n",
    "#Retour:\n",
    "#un tableau contenant les étiquettes des classes prédites des élèments de x_test\n",
    "\n",
    "  def predict(self, x_test: np.ndarray) -> np.ndarray:\n",
    "    #return np.array(list(map(lambda var : self.predict_etiquette(var), x_test)))\n",
    "    etiquettes_prediction=[]\n",
    "    for x in x_test:\n",
    "     etiquette=self.predict_etiquette(x)\n",
    "     etiquettes_prediction.append(etiquette)\n",
    "    return np.array(etiquettes_prediction)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Utilisation du classifieur\n",
    "\n",
    "a) Vous réaliserez les prédictions des étiquettes des classes sur les données *x_test* \n",
    "\n",
    "b) Vous représenterez graphiquement les données d'apprentissage et de test avec les étiquettes des classes prédites\n",
    "\n",
    "c) Vous calculerez le score d'exactitude (accuracy) de votre prédiction. Les données de test n'étant pas très bruitées vous devez obtenir 1.  \n",
    "Modifier le paramètre *noise* de la fonction qui a permis de générer les données de test, pour obtenir des données plus bruitées (ce qui va dégrader les résultats).\n",
    "Afficher aussi les valeurs de la précision et du rappel. \n",
    "\n",
    "d) Vous générerez la matrice de confusion et recalculerez les valeurs de l'exactitude, de la précision et du rappel (avec les formules vues en cours). Vous devez retrouver les résultats précédents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KnnClassifieur(3, x_train,y_train)\n",
    "prediction = knn.predict(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_train[y_train==0][:, 0], x_train[y_train==0][:, 1], c='violet')\n",
    "plt.scatter(x_train[y_train==1][:, 0], x_train[y_train==1][:, 1], c='yellow')\n",
    "\n",
    "plt.scatter(x_test[prediction==0][:, 0], x_test[prediction==0][:, 1], c='indigo')\n",
    "plt.scatter(x_test[prediction==1][:, 0], x_test[prediction==1][:, 1], c='goldenrod')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(accuracy_score(y_test, prediction))\n",
    "print(precision_score(y_test,prediction))\n",
    "print(recall_score(y_test,prediction))\n",
    "\n",
    "print(confusion_matrix(y_test,prediction))\n",
    "tn,fp,fn,tp=confusion_matrix(y_test, prediction).ravel()\n",
    "accuracy=(tp+tn)/(tp+fn+tn+fp)\n",
    "print(accuracy)\n",
    "precision=tp/(tp+fp)\n",
    "print(precision)\n",
    "rappel=tp/(tp+fn)\n",
    "print(rappel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
