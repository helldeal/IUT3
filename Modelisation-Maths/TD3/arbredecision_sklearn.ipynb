{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tLjW850U41CK"
   },
   "source": [
    "# <center>TD3: arbres de décision avec *scikit-learn* </center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qeuOIK-9tYrN"
   },
   "source": [
    "Nous allons utiliser *scikit-learn* pour mettre en place des arbres de décision. Voici le lien [doc](https://scikit-learn.org/stable/modules/tree.html) vers la documentation de *scikit-learn* concernant les arbres de décision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DhWqONh8D63I"
   },
   "outputs": [],
   "source": [
    "# Importation des packages\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Première partie: utilisation de la classe *DecisionTreeClassifier*\n",
    "\n",
    "Nous allons commencer à travailler avec le jeu de données *magasin.csv* que vous connaissez bien maintenant.\n",
    "Déterminer un dataframe *X* qui contiendra toutes les variables caractéristiques et un dataframe *Y* la variable cible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En vous aidant de la documentation de *scikit-learn*, entrainer le modèle (construction de l'arbre de décision) et faire afficher l'arbre de décision construit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez à l'aide du code ci-dessous avoir une meilleure représentation de l'arbre.\n",
    "Comparer l'arbre obtenu à celui que vous aviez construit avec votre programme écrit à la main. Il y a des différences.\n",
    "En étudiant dans la documentation, les hyperparamètres du modèle (paramètre du contructeur de *DecisionTreeClassifier*) que l'on a la possibilité  d'utiliser pour construire l'arbre, déterminer quelques différences.   \n",
    "\n",
    "> Eh oui, on est loin d'avoir implémenter complètement cet algorithme !\n",
    "> Il y a de nombreux critères à prendre en compte pour pouvoir optimiser l'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "columns = X.columns[np.logical_not(X.columns == \"Achat\")]\n",
    "\n",
    "\n",
    "dot_data = tree.export_graphviz(model_tree, out_file=None,\n",
    "                                feature_names=columns.to_list(),\n",
    "                                class_names=['non achat','achat'],\n",
    "                                filled=True, rounded=True,\n",
    "                                special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "#pour creer un pdf\n",
    "#graph.render(\"magasin\") \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seconde partie: optimisation du modèle \n",
    " \n",
    "> dans le monde de l'apprentissage automatique, on adore les néologismes issus de la langue anglaise => vous verrez souvent ce terme: *fine-tuner* le modèle. \n",
    "\n",
    "Le but sera de tester différentes valeurs des hyperparamètres du modèle pour l'optimiser. On utilisera pour cela la technique de la validation croisée comme dans le TD précédent.\n",
    "Nous utiliserons le jeu de données *iris* qui est plus volumineux que le premier utilisé. \n",
    "\n",
    "- charger le jeu de données *iris*\n",
    "- déterminer un ensemble d'apprentissage et un ensemble de test (60% apprentissage et 40% test). Dans la méthode que vous utiliserez pour construire ces deux ensembles, intéressez vous au paramètre *random_state* et passez lui la valeur maximale suggérée.\n",
    "> Le jeu de données *iris* est un jeu de données très simple dont le modèle est assez facile à déterminé. Si l'on veut voir une différence après la validation croisée sur les résultats de prédiction, il faut rendre l'apprentissage plus difficile d'où la répartition ensemble d'apprentissage et ensemble de test choisi.\n",
    "\n",
    "- construire un arbre de décision relatif à ce jeu de donnée et faire afficher l'arbre\n",
    "- calculer le score obtenu sur l'ensemble de test (exactitude)\n",
    "\n",
    "> lancer plusieurs fois votre traitement (10 fois). Qu'observez vous par rapport à la valeur de l'exactitude de la prédiction sur l'ensemble de test ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant étudier 2 hyperparamètres du modèle: *max_depth* et *min_samples_leaf*\n",
    "- regarder dans la documentation en quoi ces deux hyperparamètres influencent la construction de l'arbre. Vous pouvez tester à la main plusieurs de leurs valeurs pour visualiser les conséquences de leur modification sur le modèle obtenu.  \n",
    "- déterminer à l'aide de la technique de la validation croisée, la meilleure valeur pour les 2 hyperparamètres précédents.\n",
    "Vous utiliserai la classe *GridSearchCV* qui permet de réaliser tous les tests avec les hyperparamètres concernés et vous donnera les valeurs de ceux-ci optimisés pour maximiser l'exactitude\n",
    "[documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "et [exemple](https://www.mygreatlearning.com/blog/gridsearchcv/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Attention à l'interprétation: ce sont les meilleures valeurs des hyperparamètres de notre modèle pour le jeu de données que nous utilisons et avec la séparation que nous avons mis en place (60% apprentissage et 40% test)\n",
    "\n",
    "Utiliser les valeurs des paramètres déterminées précédemment sur la partition initiale des données (60% apprentissage et 40% test). Que constatez vous ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un autre cas à étudier\n",
    "\n",
    "\n",
    "Utiliser maintenant le jeu de données relatif au Titanic. Nous utiliserons les colonnes qui sont notées dans la cellule qui suit de ce notebook.\n",
    "\n",
    "- séparer les données en 2 ensembles: apprentissage => 80% et test=> 20%\n",
    "- construire l'arbre de décision\n",
    "- calculer le score obtenu sur l'ensemble de test\n",
    "- optimiser les hyperparamètres\n",
    "- afficher le nouveau score obtenu et les valeurs des hyperparamètres déterminées par la phase d'optimisation (les hyperparamètres à optimiser sont donnés dans la cellule qui suit de ce notebook)\n",
    "\n",
    "> attention: afin d'utiliser la classe *DecisionTreeClassifier*,  il faut que:\n",
    "- toutes les valeurs liées aux caractéristiques du jeu de données soient des nombres\n",
    "- qu'aucune valeur du jeu de données ne soit nulle (vide)  \n",
    "*Pour la colonne *Age* vous remplacerez les valeurs nulles par la moyenne de l'âge des passagers.\n",
    "Pour les valeurs nulles dans les autres colonnes, vous supprimerez la ligne du jeu de données qui correspond à cette valeur nulle.\n",
    "Il faudra donc mettre en place un pré-traitement sur les données avant de construire l'arbre.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le jeu de données complet\n",
    "#TODO\n",
    "\n",
    "# Prétraitement des données (nous allons utiliser uniquement ces colonnes)\n",
    "selected_columns = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked' ,'Survived']\n",
    "\n",
    "#TODO\n",
    "\n",
    "\n",
    "\n",
    "## les hyperparametres à optimiser et les valeurs à prendre en compte\n",
    "params = {\n",
    "    'criterion':  ['gini', 'entropy'],\n",
    "    'max_depth':  [None, 2, 4, 6, 8, 10],\n",
    "    'max_features': [None, 'sqrt', 'log2', 0.2, 0.4, 0.6, 0.8],\n",
    "    'splitter': ['best', 'random']\n",
    "}\n",
    "#TODO\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En Résumé:\n",
    "\n",
    "Les arbres de décision ont plusieurs avantages qui les rendent intéressants dans des contextes où il est utile de comprendre la séquence de décisions prise par le modèle :\n",
    "\n",
    "- Ils nécessitent peu de préparation des données (pas de normalisation, etc.).\n",
    "\n",
    "- Le coût d’utilisation des arbres est logarithmique.\n",
    "\n",
    "- Ils sont capables d’utiliser des données catégorielles et numériques.\n",
    "\n",
    "- Ils sont capables de traiter des problèmes multi-classe.\n",
    "\n",
    "- Le résultat est directement visualisable et facile à comprendre\n",
    "\n",
    "**Ces modèles présentent néanmoins deux désavantages majeurs :**\n",
    "\n",
    "- Sur-apprentissage : parfois les arbres générés sont trop complexes et généralisent mal. Choisir des bonnes valeurs pour les paramètres profondeur maximale (max_depth) et nombre minimal d’exemples par feuille (min_samples_leaf) permet d’éviter ce problème.\n",
    "\n",
    "- Il peut arriver que les arbres générés ne soient pas équilibrés (ce qui implique que le temps de parcours n’est plus logarithmique). Il est donc recommandé d’ajuster le jeu de données avant la construction, pour éviter qu’une classe domine largement les autres (en termes de nombre d’exemples d’apprentissage).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOE9pjqr0ZKO/sqrDLKutle",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Arbres de décision classifieur sklearn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
