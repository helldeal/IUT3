{"cells":[{"cell_type":"markdown","metadata":{"id":"g0B9daf8oqMQ"},"source":["# (Pré-)-Traitement Automatique des Langues\n","\n","Suivant le contexte, le terme de *Traitement Automatique des Langues* désigne les traitements de préparation (ou pré-traitements) que l'on applique au texte pour le rendre traitable par une application de \"plus haut niveau\" (e.g. découper en phrases un texte, pour déterminer les phrases les plus saillantes à faire apparaître dans un résumé). Le terme englobe aussi la désignation de ces applications de plus haut niveau ou avec utilisateur humain.\n","\n","### Objectif  \n","* analyser et interpréter les sorties et la qualité d'analyseurs linguistiques \n","* découvrir les caractéristiques (en particulier linguistiques) d'une donnée langagière qui peuvent influer sur les traitements automatiques et la qualité de ceux-ci \n","\n","\n","\n","### Thèmes abordés\n","\n","* (Pré-)traitements linguistiques\n","  * Tokenization, Sentence segmentation \n","  * POS tagging, Morphology, Lemmatization, Dependency parsing, \n","  * Named Entities Recognition (NER)\n","  * (Language Detection) \n","* Mise en application \n","  * Langue : Français \n","  * Types de texte : Dépèches journalistiques, Tweets, romans et textes juridiques\n","\n","\n","### Consignes de travail\n","\n","Réponse aux questions dans la section \"votre réponse\". Des réponses brèves et simples sont attendues. \n","\n","Vous avez le droit de modifier le code pour vous permettre de plus facilement répondre aux questions.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"CfKO-7ZT7x4y"},"source":["---\n","# Installation de l'environnement : chargement des modèles et des données\n","\n","\n","\n","\n","Executer le code suivant"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# installation de spacy\n","%pip install spacy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NhTHluRv9RIb"},"outputs":[],"source":["# Téléchargement d'un modèle pour le traitement du français\n","\n","!python -m spacy download fr_core_news_sm\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"2Z199LIHqPoc"},"outputs":[],"source":["# Importation de la bibliothèque spaCy \n","import spacy\n","\n","# Chargement du modèle pour le français\n","nlp = spacy.load(\"fr_core_news_sm\")\n","\n","# Importation d'une liste d'exemple de phrases en français\n","from spacy.lang.fr.examples import sentences "]},{"cell_type":"markdown","metadata":{"id":"y1Z4qHGSYKCV"},"source":["# Analyses linguistiques du français \n","\n","Par la suite nous utiliserons principalement la bibliothèque spaCy et sa méthode `nlp` que l'on applique à du texte brut `doc`. Avec cette méthode, spaCy réalise un certain nombre de traitements par défaut disponible dans le modèle chargé tel que la segmentation d'un texte en phrases, la tokenization, l'analyse grammaticale et morphologique des mots (dont lemmatisation), l'analyse en constituants syntaxiques, l'analyse en dépendance syntaxique, la reconnaissance des entités nommées. On désignera par `spacy_doc` l'objet qui correspond au résultat d'analyse (méthode `nlp`) de spaCy sur le texte `doc`.\n","\n","Parcourir l'objet spacy_doc comme une liste python fournira les informations rattachées à chaque token du texte. `spacy_doc.noun_chunks` donnera des informations sur les constituants syntaxiques. `spacy_doc.ents` donnera des informations sur les entités nommées détectées dans le texte.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"CQQ4CIckfKUR"},"source":["## Tokénisation\n","\n","Un **token** est une instance d'une séquence de caractères dans un document donné qui constitue une unité pour une quelconque raison (e.g. délimitée par des espaces). Les tokens qui ont une réalité grammaticale (e.g. Nom, Verbe, Adjectif...) peuvent être considérés comme des instances de **mots**. Le mot a une réalité linguistique (ses caractères sont des lettres de l'alphabet plus l'espace et le tiret). \n","\n"]},{"cell_type":"markdown","metadata":{"id":"5jh78yjel68T"},"source":["### QUESTION\n","\n","Le code suivant calcule le nombre de phrases et de tokens obtenus. \n","\n","* Faire afficher pour chaque phrase les tokens obtenus. \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MZYVlMjPfOAw"},"outputs":[],"source":["# import spaCy and define a method to tokenize via spacy\n","# en fait, la méthode récupère seulement la tokenization, mais la méthode 'nlp' \n","# produit plusieurs analyses (on le verra plus tard)\n","# machine learning based model\n","import spacy\n","spacy_tokenize = lambda text: [token.text for token in nlp(text)]\n","\n","\n","\n","# compte le nombre de phrases exemples et le nombre de tokens total obtenu \n","\n","\n","spacy_tokens = list()\n","for i in range (0, len(sentences)):\n"," \n","  spacy_tokens.extend(spacy_tokenize(sentences[i]))\n","print('len_sentences=',len(sentences),' ; len_spacy_tokens=', len(spacy_tokens))\n","print()\n","\n","#TODO affichage des tokens de chaque phrase\n","\n"]},{"cell_type":"markdown","metadata":{"id":"FwIQMphkuiNS"},"source":["\n","## Analyse lexicale\n","\n","\n","### Token vs Mot vs Formes morphologiques vs Lemme\n","\n","Le **mot** peut avoir plusieurs **formes (morphologiques)** lesquelles renseignent sur le genre, le nombre, le mode/temps; par exemples \"feuille\" et \"feuilles\" ou \"blanchir\" et \"blanchiront\". Ces variations sont propres à chaque **classe grammaticale** (e.g. nom, verbe, adjectif). On appelle **lemme** la forme référente d'un mot. \"feuille\" et \"blanchir\" sont des formes référentes.\n","\n","On appelle ces variations morphologiques des **flexions** (morphologie flexionnelle). Il existe d'autres formes de variations à base d'**affixe** (préfixe et suffixe). Ainsi \"feuillage\" et \"feuille\" sont liées par une relation de **dérivation** (morphologie dérivationnelle) et de même pour \"blanc\", \"blanchiment\" et \"blanchir\". \n","\n","Une **unité lexicale** est une unité de sens dans une langue. Ces unités peuvent être composés d'un ou plusieurs mots. Ainsi \"pomme de terre\" est aussi une **unité lexicale**. \n","\n","\n","### Propriétés associées à un token mot dans Spacy\n","\n","Les modèles de Spacy produisent de base une analyse grammaticale, morphologique et syntaxique des mots pour plusieurs langues.\n","Les propriétés suivantes informent de différents attributs (en particulier linguistiques associées) à chaque token.\n","* `text`: The original word text\n","* `lemma_`: The base form of the word.\n","* `pos_`: The simple UPOS part-of-speech tag.\n","* `tag_`: The detailed part-of-speech tag with morphological information.\n","* `dep_`: Syntactic dependency, i.e. the relation between tokens.\n","* `shape_`: The word shape – capitalization, punctuation, digits.\n","* `is_alpha`: Is the token an alpha character?\n","* `is_stop`: Is the token part of a stop list, i.e. the most common words of the language?\n","\n","Au sujet de la propriété `is_stop`, en français on parle de _mot outil_ ou de _mot vide_, vide de sens, qui ne permettent pas d'analyser le contenu \"thématique\" de la phrase. Ces mots sont en général des listes fermées et comptent les déterminants, les prépositions, et quelques adverbes. Statistiquement ils sont plus fréquents que d'autres (cf. la loi de zipf dans un prochain cours). Selon les usages, les mots vides peuvent être utiles. Par exemple, en analyse d'opinion, les adverbes de négation ou d'emphases jouent un rôle important. \n","\n"]},{"cell_type":"markdown","metadata":{"id":"9mZDBpp36KQT"},"source":["### QUESTIONS \n","Le code suivant permet d'appliquer un modèle Spacy offrant des traitements TAL à un document (ici une phrase) donné.\n","* Ajouter les propriétés permettant d'observer les résultats de la lemmatisation, de l'étiquetage grammatical, de l'analyse morphologique et de l'analyse en dépendance syntaxique. \n","* Consulter l'analyse des 5 premières phrases exemples de spacy (0 à 4). Donnez un exemple d'erreur de lemmatisation, d'erreur d'étiquetage grammatical, d'erreur d'analyse morphologique (idéalement dans des phrases différentes)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vl2wxiPM5y8S"},"outputs":[],"source":["# Ici le document est la 1ère phrase (sentence 0) des exemples de Spacy \n","# de phrases écrites en français\n","doc = sentences[2]\n","\n","# exécution des traitements en une seule commande\n","spacy_doc = nlp(doc)\n","\n","# affichage de la phrase\n","print(spacy_doc.text)\n","\n","# affichage de quelques résultats d'analyse \n","# et ce, dans une pandas dataframe pour améliorer le visuel\n","# importation de la bibliothèque pandas\n","import pandas as pd\n","# spécifie qu'au niveau de l'affichage il n'y a pas de limites, cad affiche toutes les colonnes et toutes les lignes\n","pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n","# pandas travaillant avec des listes python, on transforme le résultat d'analyse de spacy en liste\n","spacy_tokens_as_list = [(token.text, token.is_stop) for token in spacy_doc]\n","pd.DataFrame(spacy_tokens_as_list, columns=['Token', 'is_stop'])"]},{"cell_type":"markdown","metadata":{"id":"BWQAdZqp5Hir"},"source":["### VOTRE RÉPONSE\n","\n","**TODO**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Slk2dK1aq-Jo"},"outputs":[],"source":["#..."]},{"cell_type":"markdown","metadata":{"id":"C3UeYPftYmIg"},"source":["## Analyse syntaxique\n","\n","Si l'analyse lexicale vise à décrire le mot, la syntaxe a pour objet de décrire les groupes de mots et les relations entre les mots ou groupes de mots.\n","\n","En syntaxe, il existe deux modèles d'analyse de la structure syntaxique:\n","- L'**analyse en constituants** qui met en avant des groupes de mots correspondants à des catégories d'objets syntaxiques : groupe nominal, groupe verbal, groupe prépositionnel... La catégorie vient de la nature grammaticale d'un mot directeur dans le groupe de mots. Ces groupes ont une structure récursive (e.g. un groupe nominal peut contenir un groupe prépositionnel... \"L'histoire de ma vie\" contient \"de ma vie\"...). Suivant les écoles, on parle d'**analyse syntagmatique** (qui produit des  **syntagmes**) (et en anglais on parle de _chunking_ qui produit des _chunks_).\n","- L'**analyse en dépendances**  (_dependency parsing_ en anglais) qui met en avant les fonctions jouées par des têtes lexicales (e.g. sujet, objet, modifieur...) vis-à-vis d'autres mots avec lesquels ils entretiennent des relations directes. Les relations entre les mots dessinent un arbre orienté. Le verbe de la proposition principale joue le rôle de la racine. Par exemple, dans la phrase \"L'histoire de ma vie se résume simplement\". La racine est le verbe \"résume\" à partir duquel au moins deux relations directes pourront partir : l'une vers la tête du sujet à savoir le nom \"histoire\" et l'autre vers la tête du complément de manière \"simplement\". \n","\n","Les constituants peuvent jouer le rôle de termes candidats pour indexer de l'information. \n","\n","L'arbre syntaxique peut être exploitée en simplification de phrases (les mots les plus proches de la racine sont les plus importants) ou bien dans des systèmes de question-réponse pour apparier un verbe d'une question avec des arguments possibles dans des phrases contenant une réponse possible.\n","\n","Pour en savoir plus sur l'analyse syntaxique, vous pouvez consulter les chapitres 12 \"Constituency Grammars\", 13 \"Constituency Parsing\" et 14 \"Dependency Parsing\" de [Speech and Language Processing par Dan Jurafsky and James H. Martin](https://web.stanford.edu/~jurafsky/slp3). "]},{"cell_type":"markdown","metadata":{"id":"Y-x8Ysc7baMq"},"source":["### QUESTIONS : Analyse en constituants\n","Le code suivant permet d'observer les 5 premières phrases exemples. \n","\n","* A la main, identifier pour chacune des phrases les syntagmes nominaux maximums qui les composent. Le terme 'nominal' dans 'syntagme nominal' signifie que la tête sémantique (le mot le plus important du syntagme) est un nom. 'Maximum' signifie qu'il n'existe pas de constituants nominaux qui les englobent.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-n5acAV2aBYn"},"outputs":[],"source":["# Observation des 5 premières phrases exemples\n","for i in range(0,5):\n","  spacy_doc = nlp(sentences[i])\n","  print(i, spacy_doc.text)"]},{"cell_type":"markdown","metadata":{"id":"PT7E2wvnZ_5v"},"source":["* Le code suivant réalise l'identification automatique des syntagmes nominaux. Quels types d'erreurs rencontrez-vous ? Les syntagmes nominaux sont-ils raccords avec l'analyse grammaticale produite sur les tokens mots ?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dOHFhADebWV8"},"outputs":[],"source":["#spacy_noun_chunks_as_list = [(chunk.text,  chunk.root.text, chunk.root.dep_,\n","#            chunk.root.head.text) for chunk in spacy_doc.noun_chunks]\n","#pd.DataFrame(spacy_noun_chunks_as_list, columns=['text', 'root', 'dep', 'head'])\n","for i in range(0,5):\n","  spacy_doc = nlp(sentences[i])\n","  print('sentence',i, spacy_doc.text)\n","  for chunk in spacy_doc.noun_chunks:\n","    print('chunk:', chunk.text) #, chunk.root.text, chunk.root.dep_, chunk.root.head.text)   \n","  print()"]},{"cell_type":"markdown","metadata":{"id":"LADl-NVXSdQN"},"source":["### VOTRE RÉPONSE\n","\n","**TODO**\n","\n"]},{"cell_type":"markdown","metadata":{"id":"PrP0M_8dTqp_"},"source":["### QUESTIONS : Analyse en dépendance\n","\n","\n","* Avant d'exécuter le code ci-dessous, identifiez à la main les 3 mots que vous estimez le plus important dans les  5 premières phrases exemples de spacy (0 à 4). Vous pouvez appliquer la stratégie de rechercher les têtes lexicales en priorisant d'abord le verbe, puis le sujet, puis l'objet, puis les compléments.\n","\n","* Le code suivant permet de visualiser la structure syntaxique en dépendance pour chacune des 5 premières phrases exemples. Les analyses vous semblent-elles correctes ? Donnez deux exemples d'erreurs distinctes. Malgré les erreurs, retrouvez-vous vos mots dans les 3 premiers niveaux de l'arbre (le 1er niveau est la racine) ?  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wkgQPtnBs5uC"},"outputs":[],"source":["\n","# import d'une bibliothèque qui permet de visualiser les résultats de spaCy\n","# ici les liens de dépendances entre les mots\n","from spacy import displacy\n","\n","for i in range(0,5):\n","  spacy_doc = nlp(sentences[i])\n","  displacy.render(spacy_doc, style='dep', jupyter=True)"]},{"cell_type":"markdown","metadata":{"id":"Hevn0R8Aahvs"},"source":["### VOTRE RÉPONSE\n","\n","**TODO**"]},{"cell_type":"markdown","metadata":{"id":"qfwLaFdP07oQ"},"source":["## Reconnaissance d'entités nommées\n","\n","Les entités nommées sont des expressions qui désignent des noms de lieux (label `LOC`), de personnes (label `PERS`), d'organisation (label `ORG`), ou d'évènement (label `MISC`). Selon les systèmes, les dates/heures et les mesures peuvent aussi être considérées comme des entités nommées.\n","\n","\n","\n","D'un point de vue applicatif, le besoin est parfois d'identifier quelles entités sont en présence. D'autres fois, il peut importer de déterminer les positions/offsets (début/fin en termes de numéro de caractère) de l'entité nommée dans un texte."]},{"cell_type":"markdown","metadata":{"id":"xlb0dRU21zsw"},"source":["### QUESTIONS\n","\n","Le code suivant permet de visualiser entités nommées présentes dans le document analysé.\n","* Listez les types d'entités (_labels_) présentes dans les exemples\n","* Consultez l'analyse des 10 premières phrases exemples de spacy (0 à 9). Trouvez-vous des erreurs de délimitation d'entités nommées ? Dans l'étiquetage du type des entités ? Eventuellement, donner quelques exemples.\n","* Jetez un oeil sur les performances (section *accuracy evaluation*) des modèles pour le français https://spacy.io/models/fr pour avoir une idée de la performance supposée de ceux-ci. Il ne vous est pas demandé de calculer les performances sur les données exemples !"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9jkS1aoU2Brx"},"outputs":[],"source":["# le code suivant permet de visualiser entités nommées présentes dans le document analysé\n","# les offsets et le type d'entité sont aussi fournis \n","for i in range(0,9):\n","  spacy_doc = nlp(sentences[i])\n","\n","  # pour chaque entité nommé détectée dans la phrase courante\n","  for ent in spacy_doc.ents:\n","\n","    # affiche le texte de l'entité nommée, ses offsets, et son \"type\"\n","    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n","\n","  # finalement affiche la phrase en marquant visuellement les zones de textes \n","  # où une entité nommée a été repérée\n","  displacy.render(spacy_doc, style='ent', jupyter=True)"]},{"cell_type":"markdown","metadata":{"id":"liw6iMfw16KF"},"source":["### VOS RÉPONSES\n","\n","**TODO**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bm3_nGMo1B0E"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"AoBU3isucVpQ"},"source":["## Expérience personnelle vs performances attestées\n","\n","L'étiquetage grammaticale consiste à donner une étiquette à chacun des mots. Tous les mots auront une étiquette. La performance correspondra alors à combien d'étiquettes de mots sont correctement trouvés sur le nombre total de mots. On parlera de mesure d'**exactitude** (_accuracy_ en anglais, souvent abrégé en _acc_) dans ce cas.\n","\n","La reconnaissance des entités nommées est une tâche un peu différente. A l'instar de l'étiquetage grammatical, elle peut être vue comme mettre une étiquette \"entité nommée\" à certains des mots. Mais à la différence de l'étiquetage grammatical, il s'agit de déterminer les mots qui doivent recevoir une étiquette \"entité nommée\". Dans cette tâche, on évalue d'une part la capacité à retrouver TOUS LES MOTS qui portent une étiquette \"entité nommée\" ; on parlera de mesure de **rappel** (_recall_). Et d'autre part, on évalue la qualité de la prédiction (sur les mots que l'on dit porter une étiquette \"entité nommée\", combien sont correctes) ; on parlera de mesure de **précision** (_precision_) qui est similaire à la notion d'exactitude. \n","\n","Comme c'est souvent plus simple d'avoir un seul score plutôt que deux, on utilise la mesure de **F-score** qui correspond à une moyenne (harmonique) des scores de précision et de rappel.\n","\n","Si ce n'est pas clair... https://fr.wikipedia.org/wiki/Pr%C3%A9cision_et_rappel"]},{"cell_type":"markdown","metadata":{"id":"TRFF9cpUczG2"},"source":["### QUESTIONS\n","* Jeter un oeil sur les performances (section *accuracy evaluation*) du modèle utilisé pour le français https://spacy.io/models/fr pour avoir une idée de la performance supposée de celui-ci sur les tâches d'analyse linguistique (tokenization, étiquetage grammatique, lemmatisation, analyse morphologique, analyse en dépendance et reconnaissance d'entités nommées). Est-ce raccord avec ce que vous avez observé ?\n"]},{"cell_type":"markdown","metadata":{"id":"hUhWwwVGc5hA"},"source":["### VOTRE RÉPONSE\n","\n","**TODO**\n","\n"]},{"cell_type":"markdown","metadata":{"id":"q2GNFxUwaNaM"},"source":["---\n","# Analyse de textes de genres différents\n","\n","Le code suivant télécharge dans un répertoire `data` un corpus de phrases issus de 4 genres différents : textes parlementaires européens (_legal europarl_), dépèches journalistiques (_news_wikinews_), littératique romanesque (_roman verne_), et des tweets de twitter (_tweets twitter_).\n","\n","Exécuter le.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j2MikY8trjs-"},"outputs":[],"source":["!mkdir data\n","!wget -nc https://raw.githubusercontent.com/nicolashernandez/teaching_nlp/main/data/fr_raw_25000sentences_4genres.zip -P data\n","!unzip data/fr_raw_25000sentences_4genres.zip -d data"]},{"cell_type":"markdown","metadata":{"id":"mtcfjtV01OSi"},"source":["\n","## QUESTIONS\n","\n","Le code suivant charge tour à tour chacun des corpus et traite les 5 premières phrases de chaque corpus. Deux résultats de traitement sont observés : la tokenization et la reconnaissance d'entités nommées à l'aide de spaCy et du modèle pour le français précédemment utilisé.\n","\n","* Quels problèmes de tokenization relevez-vous suivant les genres de texte ? Y-a-t'il des genres pour lesquels la tokenization fonctionne mieux que d'autres ?\n","* Mêmes questions pour la reconnaissance des entités nommées.\n","* Quels corpus (et donc quels genres de texte) ont servi de données d'entraînement pour construire le modèle français utilisé ici avec spaCy (cf. https://spacy.io/models/fr) ? Est-ce que cela peut expliquer les performances observées ?  \n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"6ETeuhrev-7z"},"outputs":[{"ename":"NameError","evalue":"name 'pd' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32mc:\\Users\\alexa\\IUT3\\Modelisation-Maths\\TD7\\notebook2_analyse_linguistique.ipynb Cell 35\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/alexa/IUT3/Modelisation-Maths/TD7/notebook2_analyse_linguistique.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pd\u001b[39m.\u001b[39mset_option(\u001b[39m\"\u001b[39m\u001b[39mdisplay.max_rows\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mdisplay.max_columns\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alexa/IUT3/Modelisation-Maths/TD7/notebook2_analyse_linguistique.ipynb#X46sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m filenames \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mlegal_europarl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mnews_wikinews\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mroman_verne\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtweets_twitter\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alexa/IUT3/Modelisation-Maths/TD7/notebook2_analyse_linguistique.ipynb#X46sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m filenames:\n","\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"]}],"source":["pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n","filenames = ['legal_europarl', 'news_wikinews', 'roman_verne', 'tweets_twitter']\n","for filename in filenames:\n","  with open(\"data/\"+filename+\".txt\", 'r', encoding='UTF-8') as file:\n","    i = 0\n","    print('-->', filename.upper())\n","    print()\n","    for line in file:\n","        doc = line.rstrip()\n","        spacy_doc = nlp(doc)\n","        print('Sentence',i,':', doc)\n","        print ('spacy_tokenize:', [token.text for token in spacy_doc])\n","        if spacy_doc.ents: displacy.render(spacy_doc, style='ent', jupyter=True)\n","        #spacy_doc_as_list = [(token.text, token.lemma_, token.pos_) for token in spacy_doc]\n","#            , token.tag_,token.shape_, token.is_alpha, token.is_stop) for token in doc]\n","        #print (pd.DataFrame(spacy_doc_as_list, columns=['Token', 'Lemma', 'POS']))\n","        print ()\n","        i += 1\n","        if i==5: break\n","    print ('------------------------------------------------------------------')"]},{"cell_type":"markdown","metadata":{"id":"nBQz5q0C9_PD"},"source":["\n","## VOTRE RÉPONSE\n","\n","**TODO**\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOr6v7U81WjaT7RFPqn7a09","collapsed_sections":[],"provenance":[{"file_id":"1UlebYUnQLbU4n7NauZ4oO1bF6SPrSV0H","timestamp":1663251795047},{"file_id":"1FkWAXYaEpQiI67eG4NglZGg-SMH_BAVY","timestamp":1634855225594}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
